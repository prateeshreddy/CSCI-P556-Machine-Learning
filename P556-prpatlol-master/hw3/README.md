# CSCI-P556 - Applied Machine Learning
## Assignment: Homework 3
## Authors: Nicholas Majeske, Prateesh Reddy Patlolla

**Nicholas Majeske's submission is intended for grading**

### Question 1: The Effects of Learning Rate and Momentum
**We successfully implemented the Perceptron model and saw it converge to the specified criteria of each input pattern having absolute error less than 0.05. However, due to the high sensitivity of the model to initialization, it was not feasible to train the model for each experiment to this criteria as this could require upwards of 1 million epochs for each scenario. For this reason, the model was programmed to stop at the specified criteria and at a given number of epochs (set to 100,000).**
1. Learning Rate: Increasing learning rate generally reduces the number of epochs needed for convergence up to a point. Once the learning rate exceeds a certain threshold, stochastic gradient descent (SGD) tends to become unstable. Specifically, if the learning rate is too high, SGD fails to settle into a local minimum since the magnitude of steps causes SGD to skip, or "hop" back and forth over, a local minimum it might otherwise converge to.
2. Momentum: Using momentum increases convergence speed but the local minimum that is converged to is seldomly optimal. In the case of learning rate 0.05 and 0.1, binary cross-entropy loss (BCEL) converges to approximately 0.045 in just 6000 and and 3000 epochs with momentum compared to 92,000 and 23,000 epochs without momentum. On the other hand, in the case of learning rate 0.25 we see immediate convergence with momentum but at a very high BCEL of approximately 0.21. Compare this to the same learning curve without momentum and we see the model attains full convergence with absolute error for all patterns less than 0.05 at just over 80,000 epochs. Moreover, momentum can cause instability in SGD as seen in the case of learning rate 0.2 where at epoch 45,000 we get exploding gradients and SGD begins to "thrash". Ultimately, I think the problem with momentum is that it can exacerbate poor initializations and the likelihood of getting trapped in non-optimal local minima. The random nature of SGD is primarily used to introduce noise to the path of GD so that the model does not get stuck in non-optimal minima. In using momentum, we effectively reduce the degree of randomness in steps by drawing significantly (with alpha=0.9) from an "average" direction which does not help our model get unstuck. Thus, while momentum can give us faster convergence, the point to which our model converges may not be worth our time.

### Question 2: Summary of Results
#### What is Happening in each Learning Curve
1. Baseline: The model appears to be on the verge of overfitting in this curve as validation and testing are starting to flatline while training continue to improve.
2. Dropout: Dropout gives the best and worst performing models but significantly reduces overfitting in all instances.
    1. (p = 0.25): This model earns us our best testing set accuracy though it is only marginally better than the baseline. What makes this model fundamentally better than the baseline (in my opinion) is that the training accuracy is much closer to the validation and testing accuracies. By randomly dropping features during the training process, we are limiting the model's capability to fit to the training set. This significantly reduces our risk of overfitting.
    2. (p = 0.5): Dropping (on average) twice as many features than before causes training accuracy to fall below testing accuracy for this model. Initially this appears to be a positive result but reduced testing set accuracy suggests that this dropout rate is just slightly too high.
    3. (p = 0.75): At this magnitude of dropout rate the model is struggling to learn. However, validation and testing set accuracies appear to be equal to or greater than training over all epochs. The dropout rate is obviously too high but overfitting is still controlled with testing performance remaining equal to or greater than training.
3. Batch Normalization: No significant differnce in learning curve shape is observed but this model converges to indentical testing accuracy in half the number of epochs (23) compared to the baseline (47). Given that training was very unstable without prior initialization to [-1, 1], batch normalization would likely have produced a more stable training process without prior initialization.
4. Optimizer: These optimizers generally improve the learning curve but do not always reduce overfitting.
    1. Adadelta: Since RMSprop gave poor results with our given training parameters and professor Williamson stated that we may chose an alternative, I chose to investigate Adadelta. This optimizer gives what I believe to be the best learning curve. The model does not early stop and uses all 100 epochs during which testing accuracy exceeds training. This optimizer is very stable and effectively reduces ovefitting.
    2. Adam: The learning curve for this optimizer is very chaotic. This is likely due to the learning rate (0.05) being 50 times greater than the recommended/default setting. However, even with such a high learning rate, this optimizer produces a learning curve with less overfitting as observed in the baseline. Using this optimizer with a smaller learning rate would certainly produce superior testing set results.
    3. Nesterov: With nesterov momentum, the learning curve is very similar to the baseline and overfitting is certainly a concern. The learning curves appear slightly smoother than those in the baseline.
